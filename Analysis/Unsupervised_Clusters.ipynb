{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98a678f",
   "metadata": {},
   "source": [
    "Unsupervised Clusters</br>\n",
    "- Using the DTW distance matrices computed on gas consumption time serieses this notebook runs K-Medoids, Agglomerative, DBSCAN and Affinity Propagation clustering models and saves models creating clusters of size 3 to 22 in nested dictionaries to use as input features for Supervised learning (Supervised_Unsupervised.p). The silhouette scores of these clusters are stored as a dictionary in S_Scores.p\n",
    "- Dependencies: Merging/Unsupervised_Merge_DTW_Matrix.ipynb (DTW_Matrix_Norm.csv, DTW_Matrix_Raw.csv, Merge_Norm.csv, Merge_Raw.csv)</br>\n",
    "- Produces: Clusters_Norm.p, Clusters_Raw.p, S_Scores.p</br>\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "described-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment line below and run if not yet installed\n",
    "#! pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opponent-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/0q3fzmb57s3c187k6gjyx3_00000gn/T/ipykernel_18149/2569076438.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "\n",
    "## Additional imports can be inlcuded here\n",
    "from  sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e43edebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.858751527153705"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding potential k based on 'Rule of Thumb' √n/2\n",
    "#Decided to use 22 (√n) as the top cut off for k to add buffer, and 3 as the bottom cut off.\n",
    "data = len(pd.read_csv('../Merging/Merge_Raw.csv'))\n",
    "k = np.sqrt(data/2)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mature-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_cluster (dmatrix, k=None, d_thresh=None, compute_d = False, linkage='complete'):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        k = number of clusters or none if using distance threshold\n",
    "        d_thresh = distance threshold to use for clustering assignments\n",
    "        compute_d = False, or True if distance threshold used\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "    \n",
    "    model = AgglomerativeClustering(metric='precomputed', n_clusters=k, distance_threshold = d_thresh,\n",
    "                                    linkage=linkage, compute_distances=compute_d).fit(dmatrix)\n",
    "    \n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    results.columns = results.columns.astype(str)\n",
    "\n",
    "    k = len(results.columns)\n",
    "    if k > 3 and k < 22:\n",
    "        s_score = silhouette_score(dmatrix, labels, metric='precomputed', random_state=0)\n",
    "    else:\n",
    "        s_score = -2\n",
    "    \n",
    "    return results, s_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbccd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBSCAN_cluster(dmatrix, eps=0.5, min_samples=5, encode=True):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        eps = max distance between 2 samples to be considered in same cluster\n",
    "        min_samples = the minimum number of samples in a cluster\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "    \n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed').fit(dmatrix)\n",
    "    \n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    results.columns = results.columns.astype(str)\n",
    "    \n",
    "    k = len(results.columns)\n",
    "    if k > 3 and k < 22:\n",
    "        s_score = silhouette_score(dmatrix, labels, metric='precomputed', random_state=0)\n",
    "    else:\n",
    "        s_score = -2\n",
    "    \n",
    "    return results, s_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e854805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AffinityProp_cluster(dmatrix, damping=.9, max_iter=15, preference=None):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        dampening = damping factor - the extent to which current value is maintained relative to incoming values\n",
    "        max_iter = maximum number of iterations\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "\n",
    "    model = AffinityPropagation(damping=damping, max_iter=max_iter, affinity='precomputed', preference=preference, random_state=0).fit(dmatrix)\n",
    "    \n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    results.columns = results.columns.astype(str)\n",
    "\n",
    "    k = len(results.columns)\n",
    "    if k > 3 and k < 22:\n",
    "        s_score = silhouette_score(dmatrix, labels, metric='precomputed', random_state=0)\n",
    "    else:\n",
    "        s_score = -1\n",
    "        \n",
    "    return results, s_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unlike-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMediods_cluster (dmatrix, k=8, init='random', max_iter=300):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        k = number of clusters\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "    \n",
    "    model = KMedoids(n_clusters=k, random_state=0, metric='precomputed', method='pam', init=init, max_iter=max_iter).fit(dmatrix)\n",
    "\n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    results.columns = results.columns.astype(str)\n",
    "    \n",
    "    s_score = silhouette_score(dmatrix, labels, metric='precomputed', random_state=0)\n",
    "    \n",
    "    return results, s_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "accepted-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_clusters (K=22, norm = None, dzero=False):\n",
    "    '''Input: K = number of clusters to find\n",
    "        norm = True if using normalized rather than raw data\n",
    "        dzero = True if using dezero'd data\n",
    "    Output: results_dict =  a dictionary where the keys are the model type and parameters\n",
    "        and the values are a data frame with the labels for the particular clustering one hot encoded\n",
    "        s_scores = df of the silhouette scores for model and parameter combo, organized by s_score\n",
    "        models = a simple count of the number of models that were iterated through'''\n",
    "\n",
    "    results_dict = {'KM':{}, 'H':{}, 'DB':{}, 'AP':{}}\n",
    "    s_scores = []\n",
    "    \n",
    "    if norm:\n",
    "        dmatrix = pd.read_csv('../Merging/DTW_Matrix_Norm.csv')\n",
    "    else:\n",
    "        dmatrix = pd.read_csv('../Merging/DTW_Matrix_Raw.csv')\n",
    "\n",
    "    models = 0\n",
    "    for k in range(3,K):\n",
    "        \n",
    "        for init in ['random', 'heuristic', 'k-medoids++', 'build']:\n",
    "            for max_iter in np.arange(1, 300, 25):\n",
    "                models += 1\n",
    "                results, s_score = kMediods_cluster (dmatrix, k=k, init=init, max_iter=max_iter)\n",
    "                results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "                results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                key = f'{k}KM_I{init[:4]}_MI{max_iter}'\n",
    "                results_dict['KM'][key] = results\n",
    "                s_scores.append({'Model': 'KM', 'Parameter Key': key,\n",
    "                                'params':{'init': init, 'max_iter': max_iter},'s_score': s_score, 'k':k})\n",
    "\n",
    "        for link in ['complete', 'average', 'single']:\n",
    "                models += 1\n",
    "                results, s_score = hierarchical_cluster (dmatrix, k=k, linkage=link)\n",
    "                results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "                results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                key = f'{k}H_L{link[:4]}'\n",
    "                results_dict['H'][key] = results\n",
    "                s_scores.append({'Model': 'H', 'Parameter Key': key, \n",
    "                                 'params':{'link': link, 'dist': 'None'}, 's_score': s_score, 'k':k})\n",
    "    \n",
    "    if norm: \n",
    "        epss = np.linspace(0.000005,0.001, 26)\n",
    "        dists = np.linspace(0.025, 0.25, 26)\n",
    "    else:\n",
    "        epss = np.arange(1000,30000,1000)\n",
    "        dists = np.arange(50000000000000, 500000000000000, 20000000000000)\n",
    "\n",
    "    for eps in epss:\n",
    "        for mins in np.linspace(5, 100, 5):\n",
    "            models += 1\n",
    "            results, s_score = DBSCAN_cluster(dmatrix, eps=eps, min_samples=int(mins))\n",
    "            k = len(results.columns)\n",
    "            if s_score == -2:\n",
    "                s_score = -1\n",
    "            else:\n",
    "                results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "                results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                key = f'{k}DB_M{int(mins)}eps{round(eps,6)}'\n",
    "                results_dict['DB'][key] = results \n",
    "                s_scores.append({'Model': 'DB', 'Parameter Key': key, \n",
    "                                'params':{'eps': eps, 'mins': int(mins)}, 's_score': s_score, 'k': k,})\n",
    "                \n",
    "\n",
    "    for link in ['complete', 'average', 'single']:\n",
    "        for dist in dists:\n",
    "            models += 1\n",
    "            results, s_score = hierarchical_cluster (dmatrix, d_thresh=dist, linkage = link)\n",
    "            k = len(results.columns)\n",
    "            if s_score == -2:\n",
    "                s_score = -1\n",
    "            else:\n",
    "                results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "                results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                key = f'{k}H_L{link[:4]}_DT{round(dist,4)}'\n",
    "                results_dict['H'][key] = results\n",
    "                s_scores.append({'Model': 'H', 'Parameter Key': key,\n",
    "                                'params': {'link': link, 'dist': dist, }, 's_score': s_score, 'k':k})\n",
    "                \n",
    "    n=0\n",
    "    j=0\n",
    "    for pref in range(0,10):\n",
    "        for max_iter in range(1,15):\n",
    "            for damp in np.linspace(.5, .9, 5):\n",
    "                models += 1\n",
    "                results, s_score = AffinityProp_cluster(dmatrix, max_iter=max_iter, damping=damp, preference=pref)\n",
    "                k = len(results.columns)\n",
    "                #As AP returns 1 (or on normative sometimes 481 of 483 clusters), this makes sure that at least 1 'example' saved\n",
    "                if (n ==0 and k<len(dmatrix)) or (j ==0 and k > 1) or (k>1 and k<len(dmatrix)-2):\n",
    "                    if (n ==0 and k<len(dmatrix)):\n",
    "                        n = 1\n",
    "                    if (j ==0 and k > 1):\n",
    "                        j=1\n",
    "                    results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "                    results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                    key = f'{k}AP_MI{max_iter}_D{damp}'\n",
    "                    results_dict['AP'][key] = results\n",
    "                    s_scores.append({'Model': 'AP', 'Parameter Key': key,\n",
    "                                    'params': {'pref': pref, 'max_iter': max_iter, 'damp': damp},\n",
    "                                    's_score': s_score, 'k':k})  \n",
    "\n",
    "    s_scores = pd.DataFrame(s_scores).sort_values(by=['s_score'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return results_dict, s_scores, models\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "satisfied-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_and_norm (K=22, dzero=False):\n",
    "    '''Input: K = number of max clusters to find\n",
    "        dezero = whether to dezero or not\n",
    "    Output: results_dict = returns and saves to pickle files (split by raw and normalized version of the data) a dictionary where \n",
    "        the keys are the model and parameters and the values are a df with the labels for the particular clustering one hot encoded\n",
    "        s_scores = dictionary where keys are raw/normalized and values are dfs of models + params sorted by S-score\n",
    "        num_models = simple count of all models created in hyperparameter tuning   '''\n",
    "    \n",
    "    results_dict = {}\n",
    "    s_scores = {}\n",
    "    results_dict['norm'], s_scores['norm'], norm_models = dictionary_clusters(K=K, norm = True, dzero=dzero)\n",
    "    results_dict['raw'], s_scores['raw'], raw_models = dictionary_clusters(K=K, dzero=dzero)\n",
    "    num_models = norm_models + raw_models\n",
    "\n",
    "    #was too big a file to upload to github, so spliting dictionary into 2 groups for storage\n",
    "    #pickle.dump(results_dict, open(f\"Plant_Clusters.p\", \"wb\"))\n",
    "    pickle.dump(results_dict['norm'], open(f\"Clusters_Norm.p\", \"wb\"))\n",
    "    pickle.dump(results_dict['raw'], open(f\"Clusters_Raw.p\", \"wb\"))\n",
    "    pickle.dump(s_scores, open(f\"S_Scores.p\", \"wb\"))   \n",
    "\n",
    "    return results_dict, s_scores, num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c01f6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, scores, num_models = raw_and_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8ca88c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3760"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of total models created in hyperparameter tuning\n",
    "num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f469262c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2078"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of models meeting criteria to be evaluated (between 3-22 clusters, plus AP models)\n",
    "len(scores['raw']) + len(scores['norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "412ea6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameter Key</th>\n",
       "      <th>params</th>\n",
       "      <th>s_score</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1050</td>\n",
       "      <td>H</td>\n",
       "      <td>4H_Lsing_DT0.043</td>\n",
       "      <td>{'link': 'single', 'dist': 0.043000000000000003}</td>\n",
       "      <td>0.809829</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>H</td>\n",
       "      <td>4H_Lsing</td>\n",
       "      <td>{'link': 'single', 'dist': 'None'}</td>\n",
       "      <td>0.809829</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047</td>\n",
       "      <td>H</td>\n",
       "      <td>4H_Laver_DT0.088</td>\n",
       "      <td>{'link': 'average', 'dist': 0.088}</td>\n",
       "      <td>0.785676</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>H</td>\n",
       "      <td>4H_Laver</td>\n",
       "      <td>{'link': 'average', 'dist': 'None'}</td>\n",
       "      <td>0.785676</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>H</td>\n",
       "      <td>5H_Laver</td>\n",
       "      <td>{'link': 'average', 'dist': 'None'}</td>\n",
       "      <td>0.776311</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Model     Parameter Key  \\\n",
       "0   1050     H  4H_Lsing_DT0.043   \n",
       "1    101     H          4H_Lsing   \n",
       "2   1047     H  4H_Laver_DT0.088   \n",
       "3    100     H          4H_Laver   \n",
       "4    151     H          5H_Laver   \n",
       "\n",
       "                                             params   s_score  k  \n",
       "0  {'link': 'single', 'dist': 0.043000000000000003}  0.809829  4  \n",
       "1                {'link': 'single', 'dist': 'None'}  0.809829  4  \n",
       "2                {'link': 'average', 'dist': 0.088}  0.785676  4  \n",
       "3               {'link': 'average', 'dist': 'None'}  0.785676  4  \n",
       "4               {'link': 'average', 'dist': 'None'}  0.776311  5  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['norm'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "4ac1a698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['norm', 'raw'])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "cc4925a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['KM', 'H', 'DB', 'AP'])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters['norm'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "6756a4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plantCode</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>66596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>66597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>66612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>66613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>66614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     plantCode    0    1    2\n",
       "0            9  0.0  1.0  0.0\n",
       "1           99  0.0  1.0  0.0\n",
       "2          136  0.0  1.0  0.0\n",
       "3          298  0.0  1.0  0.0\n",
       "4          550  0.0  1.0  0.0\n",
       "..         ...  ...  ...  ...\n",
       "498      66596  0.0  1.0  0.0\n",
       "499      66597  0.0  1.0  0.0\n",
       "500      66612  0.0  1.0  0.0\n",
       "501      66613  0.0  1.0  0.0\n",
       "502      66614  0.0  1.0  0.0\n",
       "\n",
       "[503 rows x 4 columns]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters['raw']['KM']['3KM_Irand_MI1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
