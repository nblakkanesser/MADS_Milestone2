{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "described-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment line below and run if not yet installed\n",
    "#! pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "opponent-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "\n",
    "## Additional imports can be inlcuded here\n",
    "from  sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "lucky-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pds (norm=None, dezero=None, norm_vis=None):\n",
    "    '''Input: norm - if True, then the consumption values for each plant will be normalized\n",
    "        dezero - if True, then removes all plants that have a value of 0 consumption at some point\n",
    "        norm_vis - if True, then uses normalized time series for result (visualization) dataframe\n",
    "    Output: a matrix df and a results df that has timeseries and location data for each plant'''\n",
    "    if norm and dezero:\n",
    "        dmatrix = pd.read_csv('../Merging/DTW_Matrix_Norm_No0.csv')\n",
    "    elif norm:\n",
    "        dmatrix = pd.read_csv('../Merging/DTW_Matrix_Norm.csv')\n",
    "    elif dezero:\n",
    "        dmatrix = pd.read_csv('../Merging/DTW_Matrix_Raw_No0.csv')\n",
    "    else:\n",
    "        dmatrix = pd.read_csv('../Merging/DTW_Matrix_Raw.csv')\n",
    "        \n",
    "    if norm_vis:\n",
    "        results = pd.read_csv('../Merging/Merge_Norm.csv')\n",
    "    else:\n",
    "        results = pd.read_csv('../Merging/Merge_Raw.csv')\n",
    "    \n",
    "    return dmatrix, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "mature-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_cluster (dmatrix, k=None, d_thresh=None, compute_d = False, encode=True):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        k = number of clusters or none if using distance threshold\n",
    "        d_thresh = distance threshold to use for clustering assignments\n",
    "        compute_d = False, or True if distance threshold used\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "    \n",
    "    model = AgglomerativeClustering(metric='precomputed', n_clusters=k, distance_threshold = d_thresh,\n",
    "                                    linkage='complete', compute_distances=compute_d).fit(dmatrix)\n",
    "    \n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "bfbccd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBSCAN_cluster(dmatrix, eps=0.5, min_samples=5, encode=True):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        eps = max distance between 2 samples to be considered in same cluster\n",
    "        min_samples = the minimum number of samples in a cluster\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "    \n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed').fit(dmatrix)\n",
    "    \n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9e854805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AffinityProp_cluster(dmatrix, damping=.9, max_iter=15, encode=True):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        dampening = damping factor - the extent to which current value is maintained relative to incoming values\n",
    "        max_iter = maximum number of iterations\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "\n",
    "    model = AffinityPropagation(damping=damping, max_iter=max_iter, affinity='precomputed',random_state=0).fit(dmatrix)\n",
    "    \n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "unlike-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMediods_cluster (dmatrix, k=8, encode=True):\n",
    "    '''Input: dmatrix =  distance matrix of plants\n",
    "        k = number of clusters\n",
    "        encode = whether to return results with onehot encoding or not\n",
    "    Output: df of plants and their cluster labels, either one hot encoded or as one label column'''\n",
    "    \n",
    "    model = KMedoids(n_clusters=k, random_state=0, metric='precomputed').fit(dmatrix)\n",
    "\n",
    "    labels = model.labels_\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
    "    results  = pd.DataFrame(data=onehot)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "accepted-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_clusters (K=22, norm = None, dzero=False):\n",
    "    '''Input: K = number of clusters to find\n",
    "        norm = True if using normalized rather than raw data\n",
    "        dzero = True if using dezero'd data\n",
    "    Output: returns and saves to a pickle file a dictionary where the keys are the model type and parameters\n",
    "        and the values are a data frame with the labels for the particular clustering one hot encoded'''\n",
    "\n",
    "    results_dict = {}\n",
    "    dmatrix, _ = make_pds (norm=norm, dezero=dzero)\n",
    "\n",
    "    for k in range(2,K):\n",
    "        \n",
    "        for n in range(2):\n",
    "            if n == 0:\n",
    "                results = kMediods_cluster (dmatrix, k=k, encode = True)\n",
    "                d = 'KM'\n",
    "            else:\n",
    "                results = hierarchical_cluster (dmatrix, k=k, encode=True)\n",
    "                d = 'H'\n",
    "            results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "            results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                \n",
    "            if norm:\n",
    "                results.columns = [f'N_{y}' for y in results.columns]\n",
    "                results_dict[f'N_{d}{k}'] = results\n",
    "                n = 'Norm'\n",
    "            else:\n",
    "                results_dict[f'{d}{k}'] = results\n",
    "                n = 'Raw'\n",
    "    if norm: \n",
    "        for eps in np.linspace(0.000005,0.001, 20):\n",
    "            for mins in np.linspace(5, 100, 5):\n",
    "                results = DBSCAN_cluster(dmatrix, eps=eps, min_samples=int(mins))\n",
    "                d = 'DB'\n",
    "                k = len(np.unique(results.columns))\n",
    "                results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "                results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                results.columns = [f'N_{y}' for y in results.columns]\n",
    "                results_dict[f'N_{d}{k}_m{mins}eps{round(eps,6)}'] = results\n",
    "        for dist in np.linspace(0.025, 0.25, 20):\n",
    "            results = hierarchical_cluster (dmatrix, d_thresh=dist, compute_d = True, encode=True)\n",
    "            d = 'H'\n",
    "            k = len(np.unique(results.columns))\n",
    "            results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "            results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "            results.columns = [f'N_{y}' for y in results.columns]\n",
    "            results_dict[f'N_{d}{k}_d{round(dist,4)}'] = results\n",
    "    else:\n",
    "        for eps in np.arange(1000,30000,1000):\n",
    "            for mins in np.linspace(5, 100, 5):\n",
    "                results = DBSCAN_cluster(dmatrix, eps=eps, min_samples=int(mins))\n",
    "                d = 'DB'\n",
    "                k = len(np.unique(results.columns))\n",
    "                results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "                results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "                results_dict[f'{d}{k}_m{mins}eps{round(eps,6)}'] = results \n",
    "        for dist in np.linspace(50000000000000, 500000000000000, 20):\n",
    "            results = hierarchical_cluster (dmatrix, d_thresh=dist, compute_d = True, encode=True)\n",
    "            d = 'H'\n",
    "            k = len(np.unique(results.columns))\n",
    "            results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "            results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "            results.columns = [f'N_{y}' for y in results.columns]\n",
    "            results_dict[f'{d}{k}_d{dist}'] = results\n",
    "\n",
    "    results = AffinityProp_cluster(dmatrix)\n",
    "    d = 'AP'\n",
    "    k = len(np.unique(results.columns))\n",
    "    results = pd.concat([pd.Series(dmatrix.columns,name='plantCode'),results], axis=1)\n",
    "    results['plantCode'] = results['plantCode'].astype(np.int64)\n",
    "    results_dict[f'{d}{k}'] = results \n",
    "                \n",
    "    pickle.dump(results_dict, open(f\"{n}_Plant_Clusters.p\", \"wb\"))              \n",
    "    \n",
    "    return results_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "satisfied-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_and_norm (K=22, dzero=False):\n",
    "    '''Input: K = number of max clusters to find\n",
    "        dezero = whether to dezero or not\n",
    "    Output: returns and saves to a pickle file a dictionary where the keys are the model type and parameters\n",
    "        and the values are a data frame with the labels for the particular clustering one hot encoded\n",
    "        for both a raw and normalized version of the data   '''\n",
    "    norm = dictionary_clusters (K=K, norm = True, dzero=dzero)\n",
    "    raw = dictionary_clusters (K=K, dzero=dzero)\n",
    "\n",
    "    return raw, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c01f6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw, norm = raw_and_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4ac1a698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['KM2', 'H2', 'KM3', 'H3', 'KM4', 'H4', 'KM5', 'H5', 'KM6', 'H6', 'KM7', 'H7', 'KM8', 'H8', 'KM9', 'H9', 'KM10', 'H10', 'KM11', 'H11', 'KM12', 'H12', 'KM13', 'H13', 'KM14', 'H14', 'KM15', 'H15', 'KM16', 'H16', 'KM17', 'H17', 'KM18', 'H18', 'KM19', 'H19', 'KM20', 'H20', 'KM21', 'H21', 'DB4_m5.0eps1000', 'DB1_m28.75eps1000', 'DB1_m52.5eps1000', 'DB1_m76.25eps1000', 'DB1_m100.0eps1000', 'DB6_m5.0eps2000', 'DB1_m28.75eps2000', 'DB1_m52.5eps2000', 'DB1_m76.25eps2000', 'DB1_m100.0eps2000', 'DB5_m5.0eps3000', 'DB1_m28.75eps3000', 'DB1_m52.5eps3000', 'DB1_m76.25eps3000', 'DB1_m100.0eps3000', 'DB7_m5.0eps4000', 'DB1_m28.75eps4000', 'DB1_m52.5eps4000', 'DB1_m76.25eps4000', 'DB1_m100.0eps4000', 'DB8_m5.0eps5000', 'DB1_m28.75eps5000', 'DB1_m52.5eps5000', 'DB1_m76.25eps5000', 'DB1_m100.0eps5000', 'DB7_m5.0eps6000', 'DB1_m28.75eps6000', 'DB1_m52.5eps6000', 'DB1_m76.25eps6000', 'DB1_m100.0eps6000', 'DB7_m5.0eps7000', 'DB1_m28.75eps7000', 'DB1_m52.5eps7000', 'DB1_m76.25eps7000', 'DB1_m100.0eps7000', 'DB6_m5.0eps8000', 'DB1_m28.75eps8000', 'DB1_m52.5eps8000', 'DB1_m76.25eps8000', 'DB1_m100.0eps8000', 'DB6_m5.0eps9000', 'DB1_m28.75eps9000', 'DB1_m52.5eps9000', 'DB1_m76.25eps9000', 'DB1_m100.0eps9000', 'DB6_m5.0eps10000', 'DB1_m28.75eps10000', 'DB1_m52.5eps10000', 'DB1_m76.25eps10000', 'DB1_m100.0eps10000', 'DB6_m5.0eps11000', 'DB1_m28.75eps11000', 'DB1_m52.5eps11000', 'DB1_m76.25eps11000', 'DB1_m100.0eps11000', 'DB6_m5.0eps12000', 'DB1_m28.75eps12000', 'DB1_m52.5eps12000', 'DB1_m76.25eps12000', 'DB1_m100.0eps12000', 'DB6_m5.0eps13000', 'DB1_m28.75eps13000', 'DB1_m52.5eps13000', 'DB1_m76.25eps13000', 'DB1_m100.0eps13000', 'DB5_m5.0eps14000', 'DB1_m28.75eps14000', 'DB1_m52.5eps14000', 'DB1_m76.25eps14000', 'DB1_m100.0eps14000', 'DB5_m5.0eps15000', 'DB1_m28.75eps15000', 'DB1_m52.5eps15000', 'DB1_m76.25eps15000', 'DB1_m100.0eps15000', 'DB4_m5.0eps16000', 'DB1_m28.75eps16000', 'DB1_m52.5eps16000', 'DB1_m76.25eps16000', 'DB1_m100.0eps16000', 'DB4_m5.0eps17000', 'DB1_m28.75eps17000', 'DB1_m52.5eps17000', 'DB1_m76.25eps17000', 'DB1_m100.0eps17000', 'DB5_m5.0eps18000', 'DB1_m28.75eps18000', 'DB1_m52.5eps18000', 'DB1_m76.25eps18000', 'DB1_m100.0eps18000', 'DB4_m5.0eps19000', 'DB1_m28.75eps19000', 'DB1_m52.5eps19000', 'DB1_m76.25eps19000', 'DB1_m100.0eps19000', 'DB4_m5.0eps20000', 'DB1_m28.75eps20000', 'DB1_m52.5eps20000', 'DB1_m76.25eps20000', 'DB1_m100.0eps20000', 'DB3_m5.0eps21000', 'DB2_m28.75eps21000', 'DB1_m52.5eps21000', 'DB1_m76.25eps21000', 'DB1_m100.0eps21000', 'DB3_m5.0eps22000', 'DB2_m28.75eps22000', 'DB1_m52.5eps22000', 'DB1_m76.25eps22000', 'DB1_m100.0eps22000', 'DB3_m5.0eps23000', 'DB2_m28.75eps23000', 'DB1_m52.5eps23000', 'DB1_m76.25eps23000', 'DB1_m100.0eps23000', 'DB3_m5.0eps24000', 'DB2_m28.75eps24000', 'DB1_m52.5eps24000', 'DB1_m76.25eps24000', 'DB1_m100.0eps24000', 'DB3_m5.0eps25000', 'DB2_m28.75eps25000', 'DB1_m52.5eps25000', 'DB1_m76.25eps25000', 'DB1_m100.0eps25000', 'DB3_m5.0eps26000', 'DB2_m28.75eps26000', 'DB1_m52.5eps26000', 'DB1_m76.25eps26000', 'DB1_m100.0eps26000', 'DB3_m5.0eps27000', 'DB2_m28.75eps27000', 'DB1_m52.5eps27000', 'DB1_m76.25eps27000', 'DB1_m100.0eps27000', 'DB3_m5.0eps28000', 'DB2_m28.75eps28000', 'DB1_m52.5eps28000', 'DB1_m76.25eps28000', 'DB1_m100.0eps28000', 'DB3_m5.0eps29000', 'DB2_m28.75eps29000', 'DB1_m52.5eps29000', 'DB1_m76.25eps29000', 'DB1_m100.0eps29000', 'H22_d50000000000000.0', 'H15_d73684210526315.78', 'H12_d97368421052631.58', 'H10_d121052631578947.38', 'H10_d144736842105263.16', 'H9_d168421052631578.94', 'H7_d192105263157894.75', 'H6_d215789473684210.53', 'H6_d239473684210526.3', 'H6_d263157894736842.1', 'H6_d286842105263157.9', 'H5_d310526315789473.7', 'H5_d334210526315789.5', 'H5_d357894736842105.25', 'H4_d381578947368421.06', 'H4_d405263157894736.8', 'H4_d428947368421052.6', 'H4_d452631578947368.44', 'H4_d476315789473684.2', 'H4_d500000000000000.0', 'AP1'])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6756a4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plantCode</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>66596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>66597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>66612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>66613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>66614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     plantCode    0    1\n",
       "0            9  1.0  0.0\n",
       "1           99  1.0  0.0\n",
       "2          136  1.0  0.0\n",
       "3          298  1.0  0.0\n",
       "4          550  1.0  0.0\n",
       "..         ...  ...  ...\n",
       "498      66596  1.0  0.0\n",
       "499      66597  1.0  0.0\n",
       "500      66612  1.0  0.0\n",
       "501      66613  1.0  0.0\n",
       "502      66614  1.0  0.0\n",
       "\n",
       "[503 rows x 3 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['KM2']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
