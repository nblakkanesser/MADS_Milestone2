{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opponent-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/0q3fzmb57s3c187k6gjyx3_00000gn/T/ipykernel_10209/852975974.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "random-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "continental_states = ['AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA',\n",
    "           'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "current-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['MI', 'WA','TX', 'FL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92350383",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cutoff = '2022-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "central-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_state (state, normalize=None):\n",
    "    '''Input: 2-letter state abbreviation\n",
    "    Ouput: dataframe for the state that cleaned and columns paired down, and normalized if desired'''\n",
    "    df = pd.read_csv(f'../Cleaning/Plant_Location_{state}.csv')\n",
    "    df['period'] = pd.to_datetime(df['period'], format='%Y-%m').dt.to_period(freq=\"D\")\n",
    "    df= df.dropna(axis=0)\n",
    "    \n",
    "    df.rename(columns={\"total-consumption\": \"consumption\"}, inplace=True)\n",
    "    \n",
    "    df = df[['state','plantCode', 'period','consumption', 'Longitude', 'Latitude']]\n",
    "    \n",
    "    #issue with FL - some consumption numbers are \"Natural Gas = 815.8 MW\" (found with try: int(x), except: print)\n",
    "    #All non-numbers filled in with 0s...\n",
    "    df['consumption'] = pd.to_numeric(df['consumption'], errors='coerce')\n",
    "\n",
    "    df[['Longitude','Latitude','consumption']] = df[['Longitude','Latitude','consumption']].fillna(0)\n",
    "    df['plantCode'] = df['plantCode'].astype(np.int64)\n",
    "    \n",
    "    if normalize:\n",
    "        df['consumption']= df['consumption'] / df[['consumption','plantCode']].groupby('plantCode').transform('sum')['consumption']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tender-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_state_DF (states, normalize=None):\n",
    "    '''Input: list of state abbreviations\n",
    "    Output: Merged dataframe of all the states: with time periods as index and ST_plantcodes as columns'''\n",
    "    for state in states:\n",
    "        temp = cleaned_state(state, normalize)\n",
    "        try:\n",
    "            df = pd.concat([df,temp], axis=0)\n",
    "        except:\n",
    "            df = temp\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "alpha-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivoted_df (df, dezero=None):\n",
    "    '''Input df with data for all the states, and whether time series with 0 values should be dropped\n",
    "    Ouput: dataframe for the state that is formated with time periods as index and plantCodes as columns'''\n",
    "    df = df[['plantCode', 'period','consumption']]\n",
    "\n",
    "    df = pd.pivot_table(df, values='consumption', index=['period'], columns=['plantCode'])\n",
    "    \n",
    "    #get rid of columns (plants)that have 0 values?\n",
    "    #df = df.replace(0.0,np.nan)\n",
    "\n",
    "    if dezero:\n",
    "        df = df.replace(0.0,np.nan)\n",
    "        df = df.dropna(axis=1)\n",
    "\n",
    "    #Drop data for 2023!\n",
    "    for row in df.index:\n",
    "        if row >= pd.to_datetime(date_cutoff).to_period(freq=\"D\"):\n",
    "            df.drop(row, axis=0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "insured-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pairwise_dtw_cost(x, y, ret_matrix=False):\n",
    "    \"\"\"\n",
    "    Takes in two series. If ret_matrix=True, returns the full DTW cost matrix;\n",
    "    otherwise, returns only the overall DTW cost\n",
    "    \"\"\"\n",
    "    cost_matrix = np.zeros((len(x), len(y)))\n",
    "    dtw_cost = None\n",
    "    dist_fn = lambda a, b: (a - b) ** 2  # Optional helper function\n",
    "    \n",
    "    for i in range(len(x)): #x = i = row\n",
    "        for j in range(len(y)): # y = j = col\n",
    "        #If the coordinate is (0,0): define the cost matrix as d(x_(i),y_(j))\n",
    "            if i==0 and j==0:\n",
    "                cost_matrix[i,j]=dist_fn(x[i],y[j])\n",
    "        #Otherwise;\n",
    "            else:\n",
    "            #the cost matrix is equal to the sum of d(x_(i),y_(j)) and the minimum of the following:\n",
    "    #                         1)  If the row is less than or equal to zero;\n",
    "                if (i-1) < 0:\n",
    "                    up = math.inf\n",
    "                else:\n",
    "                    up = cost_matrix[j, i -1]\n",
    "    #                                      * compute the cost matrix using i and j-1\n",
    "    #                              Else: too large to compute\n",
    "    #                          2)  If the column is less than or equal to zero;\n",
    "                if (j-1) < 0:\n",
    "                    left = math.inf\n",
    "                else:\n",
    "                    left = cost_matrix[j - 1, i]\n",
    "    #                            * compute the cost matrix using i-1 and j\n",
    "    #                              Else: too large to compute\n",
    "    #                          3)  If the row and columns are less than or equal to zero;\n",
    "                if (j-1) >= 0 and (i-1) >= 0:\n",
    "                    diag =  cost_matrix[j-1, i-1] # i ==0, j==0 case already handled\n",
    "        #                                    * too large to compute\n",
    "                else:\n",
    "                    diag = math.inf\n",
    "                cost = min(up,left,diag)\n",
    "\n",
    "                cost_matrix[j,i] = dist_fn(x[i],y[j]) + cost\n",
    "    dtw_cost = cost_matrix[-1][-1]\n",
    "    \n",
    "    return cost_matrix if ret_matrix else dtw_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interpreted-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dtw_cost(df):\n",
    "    \"\"\"\n",
    "    Takes in a DataFrame and computes all pairwise DTW costs\n",
    "    \"\"\"\n",
    "    \n",
    "    dtw_cost_df = pd.DataFrame(np.zeros((len(df.columns),len(df.columns))),\n",
    "                              index=df.columns,\n",
    "                              columns=df.columns)\n",
    "    \n",
    "    for i in range(len(df.columns)):\n",
    "        for j in range(len(df.columns)):\n",
    "            if i == j:\n",
    "                pass\n",
    "            else:\n",
    "                dtw_cost_df.iloc[i,j] = calc_pairwise_dtw_cost(df.iloc[:,i], df.iloc[:,j])\n",
    "    \n",
    "    return dtw_cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bottom-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW_distance_matrix (df, output='DTW_Matrix.csv'):\n",
    "    '''Inupt: list of state abbreviations, tag to normalize or not\n",
    "    Output: Dynamic Time Warp distance matrix for all plants in states list'''\n",
    "\n",
    "    DTW = calc_dtw_cost(df)\n",
    "    \n",
    "    #Handy if computing large matrix, time intensize to run\n",
    "    DTW.to_csv(output, index=False)\n",
    "    \n",
    "    return DTW    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "other-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_DTW (states, normalize=None, output=None):\n",
    "    '''Input: state - a list of states\n",
    "        normalize - if True, then the consumption values for each plant will be normalized\n",
    "        dezero - if True, then removes all plants that have a value of 0 consumption at some point\n",
    "        output - the file name signifier for the output file\n",
    "    Output: saves specified DTW distance matrix and merged datafile'''\n",
    "    \n",
    "    raw_df = multi_state_DF (states, normalize=normalize)\n",
    "    \n",
    "    df = pivoted_df(raw_df, dezero=None)\n",
    "    #DTW_distance_matrix (df, output=f'DTW_Matrix_{output}.csv')\n",
    "    \n",
    "    timeseries = df.T\n",
    "    timeseries.reset_index(inplace=True)\n",
    "    dict_df = raw_df[['state', 'plantCode','Longitude', 'Latitude']].drop_duplicates()\n",
    "    merge = pd.merge(dict_df, timeseries, how='left', left_on='plantCode', right_on='plantCode')\n",
    "    merge = merge.fillna(0.0)\n",
    "\n",
    "    merge.to_csv(f'Merge_{output}.csv', index=False)\n",
    "    \n",
    "    #df = pivoted_df(raw_df, dezero=True)\n",
    "    #DTW_distance_matrix (df, output=f'DTW_Matrix_{output}_No0.csv')\n",
    "    \n",
    "    return print(f'Success for {output}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "respiratory-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merge_DTWs (states):\n",
    "    merge_and_DTW(states, output='Raw')\n",
    "    merge_and_DTW(states, normalize=True, output='Norm')\n",
    "    \n",
    "    return print(f'Total success for {states}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "agreed-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success for Raw\n",
      "Success for Norm\n",
      "Total success for ['MI', 'WA', 'TX', 'FL']\n"
     ]
    }
   ],
   "source": [
    "create_merge_DTWs (states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fc09f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503, 52)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Merge_Raw.csv')\n",
    "len(df), len(df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
