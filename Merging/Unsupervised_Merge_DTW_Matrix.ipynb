{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923e8151",
   "metadata": {},
   "source": [
    "Unsupervised Merge DTW Matrix</br>\n",
    "Dependencies: EIA_Plant_Data.ipynb (Plant_Location_{state}.csv files for all states to use in analysis)</br>\n",
    "Output: Merge_Norm.csv, Merge_Raw.csv, DTW_Matrix_Raw.csv, DTW_Matrix_Norm.csv (as well as No0s versions of DTWs if desired)</br></br>\n",
    "Given a list of state codes matching csv files of gas consumption data, this notebook creates time series representations of both the raw and normalized gas consumption for each plant in these states and saves them as csvs. Using these time series, this notebook then creates Dynamic Time Warping distance matrices for both the raw data consumption time series and the normalized data consumption time series for all the plants in these states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opponent-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/0q3fzmb57s3c187k6gjyx3_00000gn/T/ipykernel_27994/852975974.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "random-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "continental_states = ['AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA',\n",
    "           'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "current-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['MI', 'WA','TX', 'FL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92350383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cutoff date - otherwise will go to 2023-12-31\n",
    "date_cutoff = '2022-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "central-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_state (state, normalize=None):\n",
    "    '''Input: 2-letter state abbreviation\n",
    "    Ouput: dataframe for the state that cleaned and columns paired down, and normalized if desired'''\n",
    "    df = pd.read_csv(f'../Cleaning/Plant_Location_{state}.csv')\n",
    "    df['period'] = pd.to_datetime(df['period'], format='%Y-%m').dt.to_period(freq=\"D\")\n",
    "    df= df.dropna(axis=0)\n",
    "    \n",
    "    df.rename(columns={\"total-consumption\": \"consumption\"}, inplace=True)\n",
    "    \n",
    "    df = df[['state','plantCode', 'period','consumption', 'Longitude', 'Latitude']]\n",
    "    \n",
    "    #issue with FL - some consumption numbers are \"Natural Gas = 815.8 MW\" (found with try: int(x), except: print)\n",
    "    #All non-numbers filled in with 0s...\n",
    "    df['consumption'] = pd.to_numeric(df['consumption'], errors='coerce')\n",
    "\n",
    "    df[['Longitude','Latitude','consumption']] = df[['Longitude','Latitude','consumption']].fillna(0)\n",
    "    df['plantCode'] = df['plantCode'].astype(np.int64)\n",
    "    \n",
    "    if normalize:\n",
    "        df['consumption']= df['consumption'] / df[['consumption','plantCode']].groupby('plantCode').transform('sum')['consumption']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tender-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_state_DF (states, normalize=None):\n",
    "    '''Input: list of state abbreviations\n",
    "    Output: Merged dataframe of all the states: with time periods as index and ST_plantcodes as columns'''\n",
    "    for state in states:\n",
    "        temp = cleaned_state(state, normalize)\n",
    "        try:\n",
    "            df = pd.concat([df,temp], axis=0)\n",
    "        except:\n",
    "            df = temp\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "alpha-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivoted_df (df, dezero=None):\n",
    "    '''Input df with data for all the states, and whether time series with 0 values should be dropped\n",
    "    Ouput: dataframe for the state that is formated with time periods as index and plantCodes as columns'''\n",
    "    df = df[['plantCode', 'period','consumption']]\n",
    "\n",
    "    df = pd.pivot_table(df, values='consumption', index=['period'], columns=['plantCode'])\n",
    "    \n",
    "    #get rid of columns (plants) that have 0 values?\n",
    "    if dezero:\n",
    "        df = df.replace(0.0,np.nan)\n",
    "        df = df.dropna(axis=1)\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    #Drop data for 2023!\n",
    "    for row in df.index:\n",
    "        if row >= pd.to_datetime(date_cutoff).to_period(freq=\"D\"):\n",
    "            df.drop(row, axis=0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "insured-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pairwise_dtw_cost(x, y, ret_matrix=False):\n",
    "    \"\"\"\n",
    "    Takes in two series. If ret_matrix=True, returns the full DTW cost matrix;\n",
    "    otherwise, returns only the overall DTW cost\n",
    "    \"\"\"\n",
    "    cost_matrix = np.zeros((len(x), len(y)))\n",
    "    dtw_cost = None\n",
    "    dist_fn = lambda a, b: (a - b) ** 2  # Optional helper function\n",
    "    \n",
    "    for i in range(len(x)): #x = i = row\n",
    "        for j in range(len(y)): # y = j = col\n",
    "        #If the coordinate is (0,0): define the cost matrix as d(x_(i),y_(j))\n",
    "            if i==0 and j==0:\n",
    "                cost_matrix[i,j]=dist_fn(x[i],y[j])\n",
    "        #Otherwise;\n",
    "            else:\n",
    "            #the cost matrix is equal to the sum of d(x_(i),y_(j)) and the minimum of the following:\n",
    "    #                         1)  If the row is less than or equal to zero;\n",
    "                if (i-1) < 0:\n",
    "                    up = math.inf\n",
    "                else:\n",
    "                    up = cost_matrix[j, i -1]\n",
    "    #                                      * compute the cost matrix using i and j-1\n",
    "    #                              Else: too large to compute\n",
    "    #                          2)  If the column is less than or equal to zero;\n",
    "                if (j-1) < 0:\n",
    "                    left = math.inf\n",
    "                else:\n",
    "                    left = cost_matrix[j - 1, i]\n",
    "    #                            * compute the cost matrix using i-1 and j\n",
    "    #                              Else: too large to compute\n",
    "    #                          3)  If the row and columns are less than or equal to zero;\n",
    "                if (j-1) >= 0 and (i-1) >= 0:\n",
    "                    diag =  cost_matrix[j-1, i-1] # i ==0, j==0 case already handled\n",
    "        #                                    * too large to compute\n",
    "                else:\n",
    "                    diag = math.inf\n",
    "                cost = min(up,left,diag)\n",
    "\n",
    "                cost_matrix[j,i] = dist_fn(x[i],y[j]) + cost\n",
    "    dtw_cost = cost_matrix[-1][-1]\n",
    "    \n",
    "    return cost_matrix if ret_matrix else dtw_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interpreted-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dtw_cost(df):\n",
    "    \"\"\"\n",
    "    Takes in a DataFrame and computes all pairwise DTW costs\n",
    "    \"\"\"\n",
    "    \n",
    "    dtw_cost_df = pd.DataFrame(np.zeros((len(df.columns),len(df.columns))),\n",
    "                              index=df.columns,\n",
    "                              columns=df.columns)\n",
    "    \n",
    "    for i in range(len(df.columns)):\n",
    "        for j in range(len(df.columns)):\n",
    "            if i == j:\n",
    "                pass\n",
    "            else:\n",
    "                dtw_cost_df.iloc[i,j] = calc_pairwise_dtw_cost(df.iloc[:,i], df.iloc[:,j])\n",
    "    \n",
    "    return dtw_cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bottom-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW_distance_matrix (df, output='DTW_Matrix.csv'):\n",
    "    '''Inupt: list of state abbreviations, tag to normalize or not\n",
    "    Output: Dynamic Time Warp distance matrix for all plants in states list'''\n",
    "\n",
    "    DTW = calc_dtw_cost(df)\n",
    "    \n",
    "    #Handy if computing large matrix, time intensize to run\n",
    "    DTW.to_csv(output, index=False)\n",
    "    \n",
    "    return DTW    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "other-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_DTW (states, normalize=None, output=None):\n",
    "    '''Input: state - a list of states\n",
    "        normalize - if True, then the consumption values for each plant will be normalized\n",
    "        dezero - if True, then removes all plants that have a value of 0 consumption at some point\n",
    "        output - the file name signifier for the output file\n",
    "    Output: saves specified DTW distance matrix and merged datafile'''\n",
    "    \n",
    "    raw_df = multi_state_DF (states, normalize=normalize)\n",
    "    \n",
    "    df = pivoted_df(raw_df, dezero=None)\n",
    "    DTW_distance_matrix (df, output=f'DTW_Matrix_{output}.csv')\n",
    "    \n",
    "    timeseries = df.T\n",
    "    timeseries.reset_index(inplace=True)\n",
    "    dict_df = raw_df[['state', 'plantCode','Longitude', 'Latitude']].drop_duplicates()\n",
    "    merge = pd.merge(dict_df, timeseries, how='left', left_on='plantCode', right_on='plantCode')\n",
    "    merge = merge.fillna(0.0)\n",
    "\n",
    "    merge.to_csv(f'Merge_{output}.csv', index=False)\n",
    "    \n",
    "    #df = pivoted_df(raw_df, dezero=True)\n",
    "    #DTW_distance_matrix (df, output=f'DTW_Matrix_{output}_No0.csv')\n",
    "    \n",
    "    return print(f'Success for {output}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "respiratory-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merge_DTWs (states):\n",
    "    merge_and_DTW(states, output='Raw')\n",
    "    merge_and_DTW(states, normalize=True, output='Norm')\n",
    "    \n",
    "    return print(f'Total success for {states}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "agreed-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success for Raw\n",
      "Success for Norm\n",
      "Total success for ['MI', 'WA', 'TX', 'FL']\n"
     ]
    }
   ],
   "source": [
    "create_merge_DTWs (states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fc09f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503, 52)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Merge_Raw.csv')\n",
    "len(df), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986f0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_data (states):\n",
    "    '''Input: list of states used in the data anaylsis\n",
    "    Output: Prints out statistics on data and how many missing values were imputed with 0s when creating times serieses'''\n",
    "\n",
    "    data = 0\n",
    "    for state in states:\n",
    "        df  = pd.read_csv(f'../Cleaning/Plant_Location_{state}.csv')\n",
    "        data += len(df)\n",
    "    print(f'{data} NG Gas Consumption Data Points')\n",
    "\n",
    "    time_series = pd.read_csv(f'Merge_Raw.csv')\n",
    "    periods = len(time_series.columns)-4\n",
    "    series_data = len(time_series) * periods\n",
    "\n",
    "    missing = series_data - data\n",
    "\n",
    "    print(f'{series_data} Data Points in Time Series Data')\n",
    "    print(f'{missing} Missing Data Points Imputed with 0s')\n",
    "\n",
    "    print(f'{(missing/series_data)*100}% of Time Series Data Imputed')\n",
    "\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7958dbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23226 NG Gas Consumption Data Points\n",
      "24144 Data Points in Time Series Data\n",
      "918 Missing Data Points Imputed with 0s\n",
      "3.802186878727634% of Time Series Data Imputed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>plantCode</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>2019-01-01</th>\n",
       "      <th>2019-02-01</th>\n",
       "      <th>2019-03-01</th>\n",
       "      <th>2019-04-01</th>\n",
       "      <th>2019-05-01</th>\n",
       "      <th>2019-06-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-03-01</th>\n",
       "      <th>2022-04-01</th>\n",
       "      <th>2022-05-01</th>\n",
       "      <th>2022-06-01</th>\n",
       "      <th>2022-07-01</th>\n",
       "      <th>2022-08-01</th>\n",
       "      <th>2022-09-01</th>\n",
       "      <th>2022-10-01</th>\n",
       "      <th>2022-11-01</th>\n",
       "      <th>2022-12-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MI</td>\n",
       "      <td>57950</td>\n",
       "      <td>-82.619167</td>\n",
       "      <td>43.266389</td>\n",
       "      <td>102105.0</td>\n",
       "      <td>88115.0</td>\n",
       "      <td>81350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86083.0</td>\n",
       "      <td>109779.0</td>\n",
       "      <td>99350.0</td>\n",
       "      <td>106351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MI</td>\n",
       "      <td>57949</td>\n",
       "      <td>-83.447222</td>\n",
       "      <td>43.741111</td>\n",
       "      <td>43145.0</td>\n",
       "      <td>37347.0</td>\n",
       "      <td>42454.0</td>\n",
       "      <td>19712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31588.0</td>\n",
       "      <td>31459.0</td>\n",
       "      <td>10686.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38845.0</td>\n",
       "      <td>53431.0</td>\n",
       "      <td>43853.0</td>\n",
       "      <td>46659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI</td>\n",
       "      <td>54867</td>\n",
       "      <td>-86.644300</td>\n",
       "      <td>46.409400</td>\n",
       "      <td>11883.0</td>\n",
       "      <td>10159.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>11237.0</td>\n",
       "      <td>10643.0</td>\n",
       "      <td>11083.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11549.0</td>\n",
       "      <td>10144.0</td>\n",
       "      <td>9584.0</td>\n",
       "      <td>15025.0</td>\n",
       "      <td>20091.0</td>\n",
       "      <td>18337.0</td>\n",
       "      <td>16208.0</td>\n",
       "      <td>15731.0</td>\n",
       "      <td>10704.0</td>\n",
       "      <td>14610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MI</td>\n",
       "      <td>58427</td>\n",
       "      <td>-84.551667</td>\n",
       "      <td>42.719722</td>\n",
       "      <td>595462.0</td>\n",
       "      <td>512085.0</td>\n",
       "      <td>298345.0</td>\n",
       "      <td>344856.0</td>\n",
       "      <td>463648.0</td>\n",
       "      <td>457361.0</td>\n",
       "      <td>...</td>\n",
       "      <td>547573.0</td>\n",
       "      <td>461526.0</td>\n",
       "      <td>307599.0</td>\n",
       "      <td>456549.0</td>\n",
       "      <td>467034.0</td>\n",
       "      <td>466195.0</td>\n",
       "      <td>253597.0</td>\n",
       "      <td>419370.0</td>\n",
       "      <td>541031.0</td>\n",
       "      <td>597797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MI</td>\n",
       "      <td>62192</td>\n",
       "      <td>-82.479331</td>\n",
       "      <td>42.773716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4157779.0</td>\n",
       "      <td>4278830.0</td>\n",
       "      <td>4279821.0</td>\n",
       "      <td>4144307.0</td>\n",
       "      <td>4071685.0</td>\n",
       "      <td>3513872.0</td>\n",
       "      <td>2357711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>FL</td>\n",
       "      <td>50858</td>\n",
       "      <td>-82.340469</td>\n",
       "      <td>27.954901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>FL</td>\n",
       "      <td>10275</td>\n",
       "      <td>-81.600600</td>\n",
       "      <td>27.911400</td>\n",
       "      <td>49491.0</td>\n",
       "      <td>47142.0</td>\n",
       "      <td>51422.0</td>\n",
       "      <td>51245.0</td>\n",
       "      <td>66844.0</td>\n",
       "      <td>69119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53962.0</td>\n",
       "      <td>53814.0</td>\n",
       "      <td>65582.0</td>\n",
       "      <td>71830.0</td>\n",
       "      <td>78615.0</td>\n",
       "      <td>78811.0</td>\n",
       "      <td>68981.0</td>\n",
       "      <td>57527.0</td>\n",
       "      <td>53400.0</td>\n",
       "      <td>53814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>FL</td>\n",
       "      <td>7699</td>\n",
       "      <td>-81.849446</td>\n",
       "      <td>27.746369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>756735.0</td>\n",
       "      <td>513611.0</td>\n",
       "      <td>1046951.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1054747.0</td>\n",
       "      <td>819635.0</td>\n",
       "      <td>1114587.0</td>\n",
       "      <td>1071691.0</td>\n",
       "      <td>1042457.0</td>\n",
       "      <td>775491.0</td>\n",
       "      <td>846827.0</td>\n",
       "      <td>1115881.0</td>\n",
       "      <td>716660.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>FL</td>\n",
       "      <td>10062</td>\n",
       "      <td>-80.356600</td>\n",
       "      <td>25.835600</td>\n",
       "      <td>29428.0</td>\n",
       "      <td>24034.0</td>\n",
       "      <td>39399.0</td>\n",
       "      <td>33071.0</td>\n",
       "      <td>33795.0</td>\n",
       "      <td>36348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61371.0</td>\n",
       "      <td>43388.0</td>\n",
       "      <td>33450.0</td>\n",
       "      <td>33277.0</td>\n",
       "      <td>13440.0</td>\n",
       "      <td>18049.0</td>\n",
       "      <td>18112.0</td>\n",
       "      <td>20217.0</td>\n",
       "      <td>12939.0</td>\n",
       "      <td>9498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>FL</td>\n",
       "      <td>10008</td>\n",
       "      <td>-81.662705</td>\n",
       "      <td>30.314467</td>\n",
       "      <td>23866.0</td>\n",
       "      <td>23778.0</td>\n",
       "      <td>23418.0</td>\n",
       "      <td>27992.0</td>\n",
       "      <td>19822.0</td>\n",
       "      <td>18119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22735.0</td>\n",
       "      <td>22887.0</td>\n",
       "      <td>23730.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4432.0</td>\n",
       "      <td>26207.0</td>\n",
       "      <td>21358.0</td>\n",
       "      <td>22133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  plantCode  Longitude   Latitude  2019-01-01  2019-02-01  \\\n",
       "0      MI      57950 -82.619167  43.266389    102105.0     88115.0   \n",
       "1      MI      57949 -83.447222  43.741111     43145.0     37347.0   \n",
       "2      MI      54867 -86.644300  46.409400     11883.0     10159.0   \n",
       "3      MI      58427 -84.551667  42.719722    595462.0    512085.0   \n",
       "4      MI      62192 -82.479331  42.773716         0.0         0.0   \n",
       "..    ...        ...        ...        ...         ...         ...   \n",
       "498    FL      50858 -82.340469  27.954901         0.0         0.0   \n",
       "499    FL      10275 -81.600600  27.911400     49491.0     47142.0   \n",
       "500    FL       7699 -81.849446  27.746369         0.0         0.0   \n",
       "501    FL      10062 -80.356600  25.835600     29428.0     24034.0   \n",
       "502    FL      10008 -81.662705  30.314467     23866.0     23778.0   \n",
       "\n",
       "     2019-03-01  2019-04-01  2019-05-01  2019-06-01  ...  2022-03-01  \\\n",
       "0       81350.0         0.0         0.0         0.0  ...     98136.0   \n",
       "1       42454.0     19712.0         0.0         0.0  ...     31588.0   \n",
       "2       10886.0     11237.0     10643.0     11083.0  ...     11549.0   \n",
       "3      298345.0    344856.0    463648.0    457361.0  ...    547573.0   \n",
       "4           0.0         0.0         0.0         0.0  ...         0.0   \n",
       "..          ...         ...         ...         ...  ...         ...   \n",
       "498         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "499     51422.0     51245.0     66844.0     69119.0  ...     53962.0   \n",
       "500         0.0    756735.0    513611.0   1046951.0  ...   1054747.0   \n",
       "501     39399.0     33071.0     33795.0     36348.0  ...     61371.0   \n",
       "502     23418.0     27992.0     19822.0     18119.0  ...     22735.0   \n",
       "\n",
       "     2022-04-01  2022-05-01  2022-06-01  2022-07-01  2022-08-01  2022-09-01  \\\n",
       "0           0.0         0.0         0.0         0.0         0.0     86083.0   \n",
       "1       31459.0     10686.0         0.0         0.0         0.0     38845.0   \n",
       "2       10144.0      9584.0     15025.0     20091.0     18337.0     16208.0   \n",
       "3      461526.0    307599.0    456549.0    467034.0    466195.0    253597.0   \n",
       "4           0.0         0.0   4157779.0   4278830.0   4279821.0   4144307.0   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "498         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "499     53814.0     65582.0     71830.0     78615.0     78811.0     68981.0   \n",
       "500    819635.0   1114587.0   1071691.0   1042457.0    775491.0    846827.0   \n",
       "501     43388.0     33450.0     33277.0     13440.0     18049.0     18112.0   \n",
       "502     22887.0     23730.0       219.0       373.0         0.0      4432.0   \n",
       "\n",
       "     2022-10-01  2022-11-01  2022-12-01  \n",
       "0      109779.0     99350.0    106351.0  \n",
       "1       53431.0     43853.0     46659.0  \n",
       "2       15731.0     10704.0     14610.0  \n",
       "3      419370.0    541031.0    597797.0  \n",
       "4     4071685.0   3513872.0   2357711.0  \n",
       "..          ...         ...         ...  \n",
       "498         0.0         0.0         0.0  \n",
       "499     57527.0     53400.0     53814.0  \n",
       "500   1115881.0    716660.0         0.0  \n",
       "501     20217.0     12939.0      9498.0  \n",
       "502     26207.0     21358.0     22133.0  \n",
       "\n",
       "[503 rows x 52 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing_data(states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
